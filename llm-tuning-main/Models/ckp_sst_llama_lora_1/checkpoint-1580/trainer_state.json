{
  "best_metric": 1.1132941246032715,
  "best_model_checkpoint": "./ckp_sst_llama_lora/checkpoint-380",
  "epoch": 0.506389968350627,
  "eval_steps": 20,
  "global_step": 1580,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0,
      "grad_norm": 0.34203043580055237,
      "learning_rate": 0.00029951923076923075,
      "loss": 2.141,
      "step": 5
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.36124685406684875,
      "learning_rate": 0.00029903846153846153,
      "loss": 1.908,
      "step": 10
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.18013349175453186,
      "learning_rate": 0.00029855769230769226,
      "loss": 1.7831,
      "step": 15
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.25334909558296204,
      "learning_rate": 0.00029807692307692304,
      "loss": 1.6857,
      "step": 20
    },
    {
      "epoch": 0.01,
      "eval_loss": 1.1645957231521606,
      "eval_runtime": 214.469,
      "eval_samples_per_second": 7.139,
      "eval_steps_per_second": 0.895,
      "step": 20
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.1624867171049118,
      "learning_rate": 0.0002975961538461538,
      "loss": 1.6847,
      "step": 25
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.14059527218341827,
      "learning_rate": 0.0002971153846153846,
      "loss": 1.715,
      "step": 30
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.18531636893749237,
      "learning_rate": 0.0002966346153846154,
      "loss": 1.7208,
      "step": 35
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.10892342776060104,
      "learning_rate": 0.00029615384615384616,
      "loss": 1.695,
      "step": 40
    },
    {
      "epoch": 0.01,
      "eval_loss": 1.1366608142852783,
      "eval_runtime": 217.7556,
      "eval_samples_per_second": 7.031,
      "eval_steps_per_second": 0.882,
      "step": 40
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.12338720262050629,
      "learning_rate": 0.0002956730769230769,
      "loss": 1.6713,
      "step": 45
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.11024484038352966,
      "learning_rate": 0.00029519230769230767,
      "loss": 1.703,
      "step": 50
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.13387629389762878,
      "learning_rate": 0.0002947115384615384,
      "loss": 1.6665,
      "step": 55
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.1316831260919571,
      "learning_rate": 0.0002942307692307692,
      "loss": 1.7186,
      "step": 60
    },
    {
      "epoch": 0.02,
      "eval_loss": 1.1310381889343262,
      "eval_runtime": 218.5175,
      "eval_samples_per_second": 7.006,
      "eval_steps_per_second": 0.879,
      "step": 60
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.12288039177656174,
      "learning_rate": 0.00029374999999999996,
      "loss": 1.6732,
      "step": 65
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.11111766844987869,
      "learning_rate": 0.00029326923076923074,
      "loss": 1.6952,
      "step": 70
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.1600538045167923,
      "learning_rate": 0.0002927884615384615,
      "loss": 1.6951,
      "step": 75
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.13021151721477509,
      "learning_rate": 0.0002923076923076923,
      "loss": 1.6802,
      "step": 80
    },
    {
      "epoch": 0.03,
      "eval_loss": 1.1323448419570923,
      "eval_runtime": 217.9913,
      "eval_samples_per_second": 7.023,
      "eval_steps_per_second": 0.881,
      "step": 80
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.11993542313575745,
      "learning_rate": 0.000291826923076923,
      "loss": 1.6662,
      "step": 85
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.11269392818212509,
      "learning_rate": 0.0002913461538461538,
      "loss": 1.651,
      "step": 90
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.11777996271848679,
      "learning_rate": 0.0002908653846153846,
      "loss": 1.702,
      "step": 95
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.11256805062294006,
      "learning_rate": 0.00029038461538461537,
      "loss": 1.6978,
      "step": 100
    },
    {
      "epoch": 0.03,
      "eval_loss": 1.1318514347076416,
      "eval_runtime": 217.5703,
      "eval_samples_per_second": 7.037,
      "eval_steps_per_second": 0.882,
      "step": 100
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.15752293169498444,
      "learning_rate": 0.00028990384615384615,
      "loss": 1.6883,
      "step": 105
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.1279846578836441,
      "learning_rate": 0.00028942307692307693,
      "loss": 1.6668,
      "step": 110
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.11706648766994476,
      "learning_rate": 0.00028894230769230765,
      "loss": 1.7123,
      "step": 115
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.12400869280099869,
      "learning_rate": 0.00028846153846153843,
      "loss": 1.7087,
      "step": 120
    },
    {
      "epoch": 0.04,
      "eval_loss": 1.1252076625823975,
      "eval_runtime": 214.2097,
      "eval_samples_per_second": 7.147,
      "eval_steps_per_second": 0.896,
      "step": 120
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.10945005714893341,
      "learning_rate": 0.0002879807692307692,
      "loss": 1.6605,
      "step": 125
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.10866457223892212,
      "learning_rate": 0.0002875,
      "loss": 1.6832,
      "step": 130
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.14325857162475586,
      "learning_rate": 0.0002870192307692308,
      "loss": 1.6834,
      "step": 135
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.12469397485256195,
      "learning_rate": 0.0002865384615384615,
      "loss": 1.696,
      "step": 140
    },
    {
      "epoch": 0.04,
      "eval_loss": 1.131915807723999,
      "eval_runtime": 214.1352,
      "eval_samples_per_second": 7.15,
      "eval_steps_per_second": 0.897,
      "step": 140
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.13117165863513947,
      "learning_rate": 0.0002860576923076923,
      "loss": 1.6932,
      "step": 145
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.12342710047960281,
      "learning_rate": 0.00028557692307692306,
      "loss": 1.6718,
      "step": 150
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.1351102590560913,
      "learning_rate": 0.0002850961538461538,
      "loss": 1.6644,
      "step": 155
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.14142270386219025,
      "learning_rate": 0.00028461538461538457,
      "loss": 1.7202,
      "step": 160
    },
    {
      "epoch": 0.05,
      "eval_loss": 1.1258740425109863,
      "eval_runtime": 214.1035,
      "eval_samples_per_second": 7.151,
      "eval_steps_per_second": 0.897,
      "step": 160
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.11999478936195374,
      "learning_rate": 0.00028413461538461535,
      "loss": 1.714,
      "step": 165
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.1623978614807129,
      "learning_rate": 0.00028365384615384613,
      "loss": 1.6951,
      "step": 170
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.12220743298530579,
      "learning_rate": 0.0002831730769230769,
      "loss": 1.6977,
      "step": 175
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.13090887665748596,
      "learning_rate": 0.00028269230769230764,
      "loss": 1.6442,
      "step": 180
    },
    {
      "epoch": 0.06,
      "eval_loss": 1.1284476518630981,
      "eval_runtime": 217.3223,
      "eval_samples_per_second": 7.045,
      "eval_steps_per_second": 0.883,
      "step": 180
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.10706058889627457,
      "learning_rate": 0.0002822115384615384,
      "loss": 1.6973,
      "step": 185
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.11079712957143784,
      "learning_rate": 0.0002817307692307692,
      "loss": 1.6782,
      "step": 190
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.1208789125084877,
      "learning_rate": 0.00028125,
      "loss": 1.6456,
      "step": 195
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.1271923929452896,
      "learning_rate": 0.00028076923076923076,
      "loss": 1.6586,
      "step": 200
    },
    {
      "epoch": 0.06,
      "eval_loss": 1.1176903247833252,
      "eval_runtime": 215.7846,
      "eval_samples_per_second": 7.095,
      "eval_steps_per_second": 0.89,
      "step": 200
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.10756009817123413,
      "learning_rate": 0.00028028846153846154,
      "loss": 1.6805,
      "step": 205
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.11186575144529343,
      "learning_rate": 0.00027980769230769227,
      "loss": 1.6789,
      "step": 210
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.15058556199073792,
      "learning_rate": 0.00027932692307692305,
      "loss": 1.6582,
      "step": 215
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.11852814257144928,
      "learning_rate": 0.0002788461538461538,
      "loss": 1.6746,
      "step": 220
    },
    {
      "epoch": 0.07,
      "eval_loss": 1.1263612508773804,
      "eval_runtime": 232.4462,
      "eval_samples_per_second": 6.586,
      "eval_steps_per_second": 0.826,
      "step": 220
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.13383272290229797,
      "learning_rate": 0.0002783653846153846,
      "loss": 1.6957,
      "step": 225
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.11028864234685898,
      "learning_rate": 0.0002778846153846154,
      "loss": 1.6809,
      "step": 230
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.14366960525512695,
      "learning_rate": 0.00027740384615384617,
      "loss": 1.6279,
      "step": 235
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.10780780762434006,
      "learning_rate": 0.0002769230769230769,
      "loss": 1.6789,
      "step": 240
    },
    {
      "epoch": 0.08,
      "eval_loss": 1.120612382888794,
      "eval_runtime": 225.3237,
      "eval_samples_per_second": 6.795,
      "eval_steps_per_second": 0.852,
      "step": 240
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.12591229379177094,
      "learning_rate": 0.0002764423076923077,
      "loss": 1.6818,
      "step": 245
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.14320722222328186,
      "learning_rate": 0.0002759615384615384,
      "loss": 1.6522,
      "step": 250
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.14568430185317993,
      "learning_rate": 0.0002754807692307692,
      "loss": 1.6072,
      "step": 255
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.13567805290222168,
      "learning_rate": 0.00027499999999999996,
      "loss": 1.6265,
      "step": 260
    },
    {
      "epoch": 0.08,
      "eval_loss": 1.1268255710601807,
      "eval_runtime": 221.88,
      "eval_samples_per_second": 6.9,
      "eval_steps_per_second": 0.865,
      "step": 260
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.12889152765274048,
      "learning_rate": 0.00027451923076923074,
      "loss": 1.617,
      "step": 265
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.11926986277103424,
      "learning_rate": 0.0002740384615384615,
      "loss": 1.666,
      "step": 270
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.09904602915048599,
      "learning_rate": 0.0002735576923076923,
      "loss": 1.6793,
      "step": 275
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.11408605426549911,
      "learning_rate": 0.00027307692307692303,
      "loss": 1.6654,
      "step": 280
    },
    {
      "epoch": 0.09,
      "eval_loss": 1.12651526927948,
      "eval_runtime": 217.5149,
      "eval_samples_per_second": 7.039,
      "eval_steps_per_second": 0.883,
      "step": 280
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.10865771025419235,
      "learning_rate": 0.0002725961538461538,
      "loss": 1.6503,
      "step": 285
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.10841651260852814,
      "learning_rate": 0.0002721153846153846,
      "loss": 1.6684,
      "step": 290
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.11359800398349762,
      "learning_rate": 0.00027163461538461537,
      "loss": 1.6122,
      "step": 295
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.12580499053001404,
      "learning_rate": 0.00027115384615384615,
      "loss": 1.611,
      "step": 300
    },
    {
      "epoch": 0.1,
      "eval_loss": 1.121767520904541,
      "eval_runtime": 218.2708,
      "eval_samples_per_second": 7.014,
      "eval_steps_per_second": 0.88,
      "step": 300
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.13482137024402618,
      "learning_rate": 0.0002706730769230769,
      "loss": 1.6582,
      "step": 305
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.11972100287675858,
      "learning_rate": 0.00027019230769230766,
      "loss": 1.6375,
      "step": 310
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.10877465456724167,
      "learning_rate": 0.00026971153846153844,
      "loss": 1.7126,
      "step": 315
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.1180611103773117,
      "learning_rate": 0.0002692307692307692,
      "loss": 1.7117,
      "step": 320
    },
    {
      "epoch": 0.1,
      "eval_loss": 1.119156837463379,
      "eval_runtime": 217.213,
      "eval_samples_per_second": 7.048,
      "eval_steps_per_second": 0.884,
      "step": 320
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.11021270602941513,
      "learning_rate": 0.00026875,
      "loss": 1.6647,
      "step": 325
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.12226039171218872,
      "learning_rate": 0.0002682692307692308,
      "loss": 1.6536,
      "step": 330
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.11996394395828247,
      "learning_rate": 0.0002677884615384615,
      "loss": 1.6666,
      "step": 335
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.10948941856622696,
      "learning_rate": 0.0002673076923076923,
      "loss": 1.6872,
      "step": 340
    },
    {
      "epoch": 0.11,
      "eval_loss": 1.1254637241363525,
      "eval_runtime": 219.6116,
      "eval_samples_per_second": 6.971,
      "eval_steps_per_second": 0.874,
      "step": 340
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.11965691298246384,
      "learning_rate": 0.000266826923076923,
      "loss": 1.6576,
      "step": 345
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.10518938302993774,
      "learning_rate": 0.0002663461538461538,
      "loss": 1.6911,
      "step": 350
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.13352179527282715,
      "learning_rate": 0.0002658653846153846,
      "loss": 1.6697,
      "step": 355
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.12121903896331787,
      "learning_rate": 0.00026538461538461536,
      "loss": 1.6652,
      "step": 360
    },
    {
      "epoch": 0.12,
      "eval_loss": 1.1204198598861694,
      "eval_runtime": 214.0303,
      "eval_samples_per_second": 7.153,
      "eval_steps_per_second": 0.897,
      "step": 360
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.12539158761501312,
      "learning_rate": 0.00026490384615384614,
      "loss": 1.6938,
      "step": 365
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.11773903667926788,
      "learning_rate": 0.0002644230769230769,
      "loss": 1.6555,
      "step": 370
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.13571389019489288,
      "learning_rate": 0.00026394230769230764,
      "loss": 1.6782,
      "step": 375
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.14160986244678497,
      "learning_rate": 0.0002634615384615384,
      "loss": 1.621,
      "step": 380
    },
    {
      "epoch": 0.12,
      "eval_loss": 1.1132941246032715,
      "eval_runtime": 213.8111,
      "eval_samples_per_second": 7.161,
      "eval_steps_per_second": 0.898,
      "step": 380
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.11955776810646057,
      "learning_rate": 0.0002629807692307692,
      "loss": 1.605,
      "step": 385
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.14612144231796265,
      "learning_rate": 0.0002625,
      "loss": 1.6336,
      "step": 390
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.12832781672477722,
      "learning_rate": 0.00026201923076923076,
      "loss": 1.6349,
      "step": 395
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.13828399777412415,
      "learning_rate": 0.00026153846153846154,
      "loss": 1.6418,
      "step": 400
    },
    {
      "epoch": 0.13,
      "eval_loss": 1.126295804977417,
      "eval_runtime": 213.4342,
      "eval_samples_per_second": 7.173,
      "eval_steps_per_second": 0.9,
      "step": 400
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.12191557139158249,
      "learning_rate": 0.00026105769230769227,
      "loss": 1.6731,
      "step": 405
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.12913928925991058,
      "learning_rate": 0.00026057692307692305,
      "loss": 1.6559,
      "step": 410
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.1355920433998108,
      "learning_rate": 0.00026009615384615383,
      "loss": 1.6474,
      "step": 415
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.12386402487754822,
      "learning_rate": 0.0002596153846153846,
      "loss": 1.659,
      "step": 420
    },
    {
      "epoch": 0.13,
      "eval_loss": 1.127407431602478,
      "eval_runtime": 213.4759,
      "eval_samples_per_second": 7.172,
      "eval_steps_per_second": 0.899,
      "step": 420
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.19084589183330536,
      "learning_rate": 0.0002591346153846154,
      "loss": 1.6942,
      "step": 425
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.12727470695972443,
      "learning_rate": 0.0002586538461538461,
      "loss": 1.6215,
      "step": 430
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.13449449837207794,
      "learning_rate": 0.0002581730769230769,
      "loss": 1.6889,
      "step": 435
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.1231970563530922,
      "learning_rate": 0.0002576923076923077,
      "loss": 1.65,
      "step": 440
    },
    {
      "epoch": 0.14,
      "eval_loss": 1.1268720626831055,
      "eval_runtime": 213.1938,
      "eval_samples_per_second": 7.181,
      "eval_steps_per_second": 0.901,
      "step": 440
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.1274077594280243,
      "learning_rate": 0.0002572115384615384,
      "loss": 1.6809,
      "step": 445
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.11375348269939423,
      "learning_rate": 0.0002567307692307692,
      "loss": 1.6744,
      "step": 450
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.11989951133728027,
      "learning_rate": 0.00025624999999999997,
      "loss": 1.6612,
      "step": 455
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.1088775098323822,
      "learning_rate": 0.00025576923076923075,
      "loss": 1.6722,
      "step": 460
    },
    {
      "epoch": 0.15,
      "eval_loss": 1.122620940208435,
      "eval_runtime": 213.1936,
      "eval_samples_per_second": 7.181,
      "eval_steps_per_second": 0.901,
      "step": 460
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.12013348937034607,
      "learning_rate": 0.00025528846153846153,
      "loss": 1.6553,
      "step": 465
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.1314215511083603,
      "learning_rate": 0.00025480769230769225,
      "loss": 1.6451,
      "step": 470
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.12740084528923035,
      "learning_rate": 0.00025432692307692304,
      "loss": 1.6495,
      "step": 475
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.11776824295520782,
      "learning_rate": 0.0002538461538461538,
      "loss": 1.6364,
      "step": 480
    },
    {
      "epoch": 0.15,
      "eval_loss": 1.1245176792144775,
      "eval_runtime": 213.1032,
      "eval_samples_per_second": 7.184,
      "eval_steps_per_second": 0.901,
      "step": 480
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.12046880275011063,
      "learning_rate": 0.0002533653846153846,
      "loss": 1.6566,
      "step": 485
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.13976742327213287,
      "learning_rate": 0.0002528846153846154,
      "loss": 1.6779,
      "step": 490
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.16087117791175842,
      "learning_rate": 0.00025240384615384616,
      "loss": 1.6318,
      "step": 495
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.12434904277324677,
      "learning_rate": 0.0002519230769230769,
      "loss": 1.6638,
      "step": 500
    },
    {
      "epoch": 0.16,
      "eval_loss": 1.1219996213912964,
      "eval_runtime": 213.0816,
      "eval_samples_per_second": 7.185,
      "eval_steps_per_second": 0.901,
      "step": 500
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.13322755694389343,
      "learning_rate": 0.00025144230769230766,
      "loss": 1.6745,
      "step": 505
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.12014992535114288,
      "learning_rate": 0.00025096153846153844,
      "loss": 1.6754,
      "step": 510
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.12091439962387085,
      "learning_rate": 0.0002504807692307692,
      "loss": 1.6601,
      "step": 515
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.14018487930297852,
      "learning_rate": 0.00025,
      "loss": 1.6796,
      "step": 520
    },
    {
      "epoch": 0.17,
      "eval_loss": 1.1289836168289185,
      "eval_runtime": 213.3962,
      "eval_samples_per_second": 7.174,
      "eval_steps_per_second": 0.9,
      "step": 520
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.12273547053337097,
      "learning_rate": 0.0002495192307692308,
      "loss": 1.6973,
      "step": 525
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.153753861784935,
      "learning_rate": 0.0002490384615384615,
      "loss": 1.649,
      "step": 530
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.12561951577663422,
      "learning_rate": 0.0002485576923076923,
      "loss": 1.663,
      "step": 535
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.13816624879837036,
      "learning_rate": 0.000248076923076923,
      "loss": 1.6414,
      "step": 540
    },
    {
      "epoch": 0.17,
      "eval_loss": 1.1225190162658691,
      "eval_runtime": 213.0225,
      "eval_samples_per_second": 7.187,
      "eval_steps_per_second": 0.901,
      "step": 540
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.13811951875686646,
      "learning_rate": 0.0002475961538461538,
      "loss": 1.6578,
      "step": 545
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.146794393658638,
      "learning_rate": 0.0002471153846153846,
      "loss": 1.6175,
      "step": 550
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.1330181211233139,
      "learning_rate": 0.00024663461538461536,
      "loss": 1.6415,
      "step": 555
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.12576651573181152,
      "learning_rate": 0.00024615384615384614,
      "loss": 1.6693,
      "step": 560
    },
    {
      "epoch": 0.18,
      "eval_loss": 1.1253001689910889,
      "eval_runtime": 212.8316,
      "eval_samples_per_second": 7.193,
      "eval_steps_per_second": 0.902,
      "step": 560
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.1678924709558487,
      "learning_rate": 0.0002456730769230769,
      "loss": 1.6739,
      "step": 565
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.1392790675163269,
      "learning_rate": 0.00024519230769230765,
      "loss": 1.6643,
      "step": 570
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.1227354034781456,
      "learning_rate": 0.00024471153846153843,
      "loss": 1.6212,
      "step": 575
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.13479067385196686,
      "learning_rate": 0.0002442307692307692,
      "loss": 1.6529,
      "step": 580
    },
    {
      "epoch": 0.19,
      "eval_loss": 1.115480661392212,
      "eval_runtime": 213.728,
      "eval_samples_per_second": 7.163,
      "eval_steps_per_second": 0.898,
      "step": 580
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.1296975314617157,
      "learning_rate": 0.00024375,
      "loss": 1.6359,
      "step": 585
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.14858947694301605,
      "learning_rate": 0.00024326923076923074,
      "loss": 1.6536,
      "step": 590
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.13553766906261444,
      "learning_rate": 0.00024278846153846152,
      "loss": 1.6407,
      "step": 595
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.13170719146728516,
      "learning_rate": 0.0002423076923076923,
      "loss": 1.6571,
      "step": 600
    },
    {
      "epoch": 0.19,
      "eval_loss": 1.1182421445846558,
      "eval_runtime": 212.9731,
      "eval_samples_per_second": 7.189,
      "eval_steps_per_second": 0.902,
      "step": 600
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.12687236070632935,
      "learning_rate": 0.00024182692307692306,
      "loss": 1.6504,
      "step": 605
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.12906496226787567,
      "learning_rate": 0.00024134615384615384,
      "loss": 1.6848,
      "step": 610
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.1616310030221939,
      "learning_rate": 0.00024086538461538462,
      "loss": 1.6572,
      "step": 615
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.11583501100540161,
      "learning_rate": 0.00024038461538461537,
      "loss": 1.6559,
      "step": 620
    },
    {
      "epoch": 0.2,
      "eval_loss": 1.1260579824447632,
      "eval_runtime": 212.9505,
      "eval_samples_per_second": 7.189,
      "eval_steps_per_second": 0.902,
      "step": 620
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.11473198980093002,
      "learning_rate": 0.00023990384615384615,
      "loss": 1.6962,
      "step": 625
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.12164720892906189,
      "learning_rate": 0.0002394230769230769,
      "loss": 1.6795,
      "step": 630
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.13245292007923126,
      "learning_rate": 0.00023894230769230766,
      "loss": 1.6929,
      "step": 635
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.12883228063583374,
      "learning_rate": 0.00023846153846153844,
      "loss": 1.653,
      "step": 640
    },
    {
      "epoch": 0.21,
      "eval_loss": 1.1288118362426758,
      "eval_runtime": 213.9626,
      "eval_samples_per_second": 7.155,
      "eval_steps_per_second": 0.897,
      "step": 640
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.12299086898565292,
      "learning_rate": 0.0002379807692307692,
      "loss": 1.6632,
      "step": 645
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.12648844718933105,
      "learning_rate": 0.00023749999999999997,
      "loss": 1.6573,
      "step": 650
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.12525348365306854,
      "learning_rate": 0.00023701923076923073,
      "loss": 1.6687,
      "step": 655
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.14355117082595825,
      "learning_rate": 0.0002365384615384615,
      "loss": 1.6735,
      "step": 660
    },
    {
      "epoch": 0.21,
      "eval_loss": 1.122697353363037,
      "eval_runtime": 212.9207,
      "eval_samples_per_second": 7.19,
      "eval_steps_per_second": 0.902,
      "step": 660
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.13575124740600586,
      "learning_rate": 0.0002360576923076923,
      "loss": 1.672,
      "step": 665
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.12834009528160095,
      "learning_rate": 0.00023557692307692304,
      "loss": 1.6467,
      "step": 670
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.1245671808719635,
      "learning_rate": 0.00023509615384615382,
      "loss": 1.6637,
      "step": 675
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.13121026754379272,
      "learning_rate": 0.0002346153846153846,
      "loss": 1.6571,
      "step": 680
    },
    {
      "epoch": 0.22,
      "eval_loss": 1.1271697282791138,
      "eval_runtime": 212.8947,
      "eval_samples_per_second": 7.191,
      "eval_steps_per_second": 0.902,
      "step": 680
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.1535130888223648,
      "learning_rate": 0.00023413461538461535,
      "loss": 1.6514,
      "step": 685
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.13751356303691864,
      "learning_rate": 0.00023365384615384613,
      "loss": 1.6547,
      "step": 690
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.11714992672204971,
      "learning_rate": 0.00023317307692307692,
      "loss": 1.6326,
      "step": 695
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.11864188313484192,
      "learning_rate": 0.00023269230769230767,
      "loss": 1.614,
      "step": 700
    },
    {
      "epoch": 0.22,
      "eval_loss": 1.122786521911621,
      "eval_runtime": 212.8228,
      "eval_samples_per_second": 7.194,
      "eval_steps_per_second": 0.902,
      "step": 700
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.12922273576259613,
      "learning_rate": 0.00023221153846153845,
      "loss": 1.6252,
      "step": 705
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.1500522792339325,
      "learning_rate": 0.00023173076923076923,
      "loss": 1.639,
      "step": 710
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.14974382519721985,
      "learning_rate": 0.00023124999999999998,
      "loss": 1.6367,
      "step": 715
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.13166333734989166,
      "learning_rate": 0.00023076923076923076,
      "loss": 1.636,
      "step": 720
    },
    {
      "epoch": 0.23,
      "eval_loss": 1.1277995109558105,
      "eval_runtime": 212.9995,
      "eval_samples_per_second": 7.188,
      "eval_steps_per_second": 0.901,
      "step": 720
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.18390342593193054,
      "learning_rate": 0.00023028846153846154,
      "loss": 1.681,
      "step": 725
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.15603575110435486,
      "learning_rate": 0.0002298076923076923,
      "loss": 1.5904,
      "step": 730
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.12519954144954681,
      "learning_rate": 0.00022932692307692305,
      "loss": 1.6174,
      "step": 735
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.13721880316734314,
      "learning_rate": 0.0002288461538461538,
      "loss": 1.6701,
      "step": 740
    },
    {
      "epoch": 0.24,
      "eval_loss": 1.1207810640335083,
      "eval_runtime": 212.8415,
      "eval_samples_per_second": 7.193,
      "eval_steps_per_second": 0.902,
      "step": 740
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.12126733362674713,
      "learning_rate": 0.00022836538461538458,
      "loss": 1.6623,
      "step": 745
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.16185183823108673,
      "learning_rate": 0.00022788461538461537,
      "loss": 1.6767,
      "step": 750
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.13962824642658234,
      "learning_rate": 0.00022740384615384612,
      "loss": 1.6232,
      "step": 755
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.13226358592510223,
      "learning_rate": 0.0002269230769230769,
      "loss": 1.6493,
      "step": 760
    },
    {
      "epoch": 0.24,
      "eval_loss": 1.1250660419464111,
      "eval_runtime": 212.8499,
      "eval_samples_per_second": 7.193,
      "eval_steps_per_second": 0.902,
      "step": 760
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.1263437420129776,
      "learning_rate": 0.00022644230769230768,
      "loss": 1.6668,
      "step": 765
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.1377338171005249,
      "learning_rate": 0.00022596153846153843,
      "loss": 1.6347,
      "step": 770
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.18131829798221588,
      "learning_rate": 0.0002254807692307692,
      "loss": 1.6499,
      "step": 775
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.22689616680145264,
      "learning_rate": 0.000225,
      "loss": 1.6436,
      "step": 780
    },
    {
      "epoch": 0.25,
      "eval_loss": 1.1263272762298584,
      "eval_runtime": 212.8582,
      "eval_samples_per_second": 7.193,
      "eval_steps_per_second": 0.902,
      "step": 780
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.14194577932357788,
      "learning_rate": 0.00022451923076923075,
      "loss": 1.6538,
      "step": 785
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.14298611879348755,
      "learning_rate": 0.00022403846153846153,
      "loss": 1.6253,
      "step": 790
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.16401278972625732,
      "learning_rate": 0.00022355769230769228,
      "loss": 1.6518,
      "step": 795
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.13212850689888,
      "learning_rate": 0.00022307692307692306,
      "loss": 1.6639,
      "step": 800
    },
    {
      "epoch": 0.26,
      "eval_loss": 1.1246169805526733,
      "eval_runtime": 212.8913,
      "eval_samples_per_second": 7.191,
      "eval_steps_per_second": 0.902,
      "step": 800
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.13372702896595,
      "learning_rate": 0.00022259615384615384,
      "loss": 1.6538,
      "step": 805
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.12190394103527069,
      "learning_rate": 0.0002221153846153846,
      "loss": 1.6605,
      "step": 810
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.13517622649669647,
      "learning_rate": 0.00022163461538461538,
      "loss": 1.6494,
      "step": 815
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.14489568769931793,
      "learning_rate": 0.00022115384615384616,
      "loss": 1.6682,
      "step": 820
    },
    {
      "epoch": 0.26,
      "eval_loss": 1.1208431720733643,
      "eval_runtime": 212.8904,
      "eval_samples_per_second": 7.191,
      "eval_steps_per_second": 0.902,
      "step": 820
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.12190630286931992,
      "learning_rate": 0.0002206730769230769,
      "loss": 1.6352,
      "step": 825
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.13217948377132416,
      "learning_rate": 0.00022019230769230766,
      "loss": 1.6535,
      "step": 830
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.13579295575618744,
      "learning_rate": 0.00021971153846153842,
      "loss": 1.6509,
      "step": 835
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.17994172871112823,
      "learning_rate": 0.0002192307692307692,
      "loss": 1.6067,
      "step": 840
    },
    {
      "epoch": 0.27,
      "eval_loss": 1.1255545616149902,
      "eval_runtime": 212.8985,
      "eval_samples_per_second": 7.191,
      "eval_steps_per_second": 0.902,
      "step": 840
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.11922335624694824,
      "learning_rate": 0.00021874999999999998,
      "loss": 1.6545,
      "step": 845
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.134770929813385,
      "learning_rate": 0.00021826923076923073,
      "loss": 1.6469,
      "step": 850
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.13286587595939636,
      "learning_rate": 0.0002177884615384615,
      "loss": 1.6158,
      "step": 855
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.14354558289051056,
      "learning_rate": 0.0002173076923076923,
      "loss": 1.6227,
      "step": 860
    },
    {
      "epoch": 0.28,
      "eval_loss": 1.1252312660217285,
      "eval_runtime": 212.9253,
      "eval_samples_per_second": 7.19,
      "eval_steps_per_second": 0.902,
      "step": 860
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.12581443786621094,
      "learning_rate": 0.00021682692307692305,
      "loss": 1.6583,
      "step": 865
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.13969892263412476,
      "learning_rate": 0.00021634615384615383,
      "loss": 1.6674,
      "step": 870
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.12400558590888977,
      "learning_rate": 0.0002158653846153846,
      "loss": 1.6633,
      "step": 875
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.15871453285217285,
      "learning_rate": 0.00021538461538461536,
      "loss": 1.6106,
      "step": 880
    },
    {
      "epoch": 0.28,
      "eval_loss": 1.1232411861419678,
      "eval_runtime": 212.8868,
      "eval_samples_per_second": 7.192,
      "eval_steps_per_second": 0.902,
      "step": 880
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.13635431230068207,
      "learning_rate": 0.00021490384615384614,
      "loss": 1.6531,
      "step": 885
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.2014157772064209,
      "learning_rate": 0.00021442307692307692,
      "loss": 1.6573,
      "step": 890
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.13004793226718903,
      "learning_rate": 0.00021394230769230767,
      "loss": 1.6382,
      "step": 895
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.1578235775232315,
      "learning_rate": 0.00021346153846153845,
      "loss": 1.5876,
      "step": 900
    },
    {
      "epoch": 0.29,
      "eval_loss": 1.1229174137115479,
      "eval_runtime": 212.8751,
      "eval_samples_per_second": 7.192,
      "eval_steps_per_second": 0.902,
      "step": 900
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.13407282531261444,
      "learning_rate": 0.00021298076923076923,
      "loss": 1.6404,
      "step": 905
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.1485946625471115,
      "learning_rate": 0.0002125,
      "loss": 1.6073,
      "step": 910
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.15761905908584595,
      "learning_rate": 0.00021201923076923077,
      "loss": 1.6617,
      "step": 915
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.17446811497211456,
      "learning_rate": 0.00021153846153846152,
      "loss": 1.6222,
      "step": 920
    },
    {
      "epoch": 0.29,
      "eval_loss": 1.1225595474243164,
      "eval_runtime": 212.916,
      "eval_samples_per_second": 7.191,
      "eval_steps_per_second": 0.902,
      "step": 920
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.14972414076328278,
      "learning_rate": 0.0002110576923076923,
      "loss": 1.6321,
      "step": 925
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.15699976682662964,
      "learning_rate": 0.00021057692307692306,
      "loss": 1.5965,
      "step": 930
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.14347663521766663,
      "learning_rate": 0.0002100961538461538,
      "loss": 1.644,
      "step": 935
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.1341836005449295,
      "learning_rate": 0.0002096153846153846,
      "loss": 1.6718,
      "step": 940
    },
    {
      "epoch": 0.3,
      "eval_loss": 1.1289548873901367,
      "eval_runtime": 212.8911,
      "eval_samples_per_second": 7.191,
      "eval_steps_per_second": 0.902,
      "step": 940
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.1307593584060669,
      "learning_rate": 0.00020913461538461534,
      "loss": 1.6736,
      "step": 945
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.14119525253772736,
      "learning_rate": 0.00020865384615384612,
      "loss": 1.6248,
      "step": 950
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.13894805312156677,
      "learning_rate": 0.0002081730769230769,
      "loss": 1.64,
      "step": 955
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.13012443482875824,
      "learning_rate": 0.00020769230769230766,
      "loss": 1.6429,
      "step": 960
    },
    {
      "epoch": 0.31,
      "eval_loss": 1.1200472116470337,
      "eval_runtime": 212.9055,
      "eval_samples_per_second": 7.191,
      "eval_steps_per_second": 0.902,
      "step": 960
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.1263604611158371,
      "learning_rate": 0.00020721153846153844,
      "loss": 1.6695,
      "step": 965
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.14282779395580292,
      "learning_rate": 0.00020673076923076922,
      "loss": 1.6331,
      "step": 970
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.17206694185733795,
      "learning_rate": 0.00020624999999999997,
      "loss": 1.6531,
      "step": 975
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.27594006061553955,
      "learning_rate": 0.00020576923076923075,
      "loss": 1.6555,
      "step": 980
    },
    {
      "epoch": 0.31,
      "eval_loss": 1.120912790298462,
      "eval_runtime": 212.937,
      "eval_samples_per_second": 7.19,
      "eval_steps_per_second": 0.902,
      "step": 980
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.12709581851959229,
      "learning_rate": 0.00020528846153846153,
      "loss": 1.6086,
      "step": 985
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.1603756844997406,
      "learning_rate": 0.00020480769230769229,
      "loss": 1.6195,
      "step": 990
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.19016338884830475,
      "learning_rate": 0.00020432692307692307,
      "loss": 1.6721,
      "step": 995
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.15442641079425812,
      "learning_rate": 0.00020384615384615385,
      "loss": 1.641,
      "step": 1000
    },
    {
      "epoch": 0.32,
      "eval_loss": 1.121212363243103,
      "eval_runtime": 212.9434,
      "eval_samples_per_second": 7.19,
      "eval_steps_per_second": 0.902,
      "step": 1000
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.12935656309127808,
      "learning_rate": 0.0002033653846153846,
      "loss": 1.6507,
      "step": 1005
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.1576061099767685,
      "learning_rate": 0.00020288461538461538,
      "loss": 1.6746,
      "step": 1010
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.16504183411598206,
      "learning_rate": 0.00020240384615384616,
      "loss": 1.6468,
      "step": 1015
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.17606410384178162,
      "learning_rate": 0.00020192307692307691,
      "loss": 1.6316,
      "step": 1020
    },
    {
      "epoch": 0.33,
      "eval_loss": 1.1226869821548462,
      "eval_runtime": 212.958,
      "eval_samples_per_second": 7.189,
      "eval_steps_per_second": 0.902,
      "step": 1020
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.1457127183675766,
      "learning_rate": 0.00020144230769230767,
      "loss": 1.6622,
      "step": 1025
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.12717260420322418,
      "learning_rate": 0.00020096153846153842,
      "loss": 1.6348,
      "step": 1030
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.13511084020137787,
      "learning_rate": 0.0002004807692307692,
      "loss": 1.63,
      "step": 1035
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.1955212950706482,
      "learning_rate": 0.00019999999999999998,
      "loss": 1.6175,
      "step": 1040
    },
    {
      "epoch": 0.33,
      "eval_loss": 1.1208242177963257,
      "eval_runtime": 212.9076,
      "eval_samples_per_second": 7.191,
      "eval_steps_per_second": 0.902,
      "step": 1040
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.14404946565628052,
      "learning_rate": 0.00019951923076923074,
      "loss": 1.6158,
      "step": 1045
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.14498957991600037,
      "learning_rate": 0.00019903846153846152,
      "loss": 1.6288,
      "step": 1050
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.14541536569595337,
      "learning_rate": 0.0001985576923076923,
      "loss": 1.6395,
      "step": 1055
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.1447821408510208,
      "learning_rate": 0.00019807692307692305,
      "loss": 1.6806,
      "step": 1060
    },
    {
      "epoch": 0.34,
      "eval_loss": 1.1231119632720947,
      "eval_runtime": 212.9305,
      "eval_samples_per_second": 7.19,
      "eval_steps_per_second": 0.902,
      "step": 1060
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.14077575504779816,
      "learning_rate": 0.00019759615384615383,
      "loss": 1.6241,
      "step": 1065
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.15343999862670898,
      "learning_rate": 0.00019711538461538458,
      "loss": 1.6258,
      "step": 1070
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.20414093136787415,
      "learning_rate": 0.00019663461538461536,
      "loss": 1.6387,
      "step": 1075
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.16805709898471832,
      "learning_rate": 0.00019615384615384615,
      "loss": 1.6341,
      "step": 1080
    },
    {
      "epoch": 0.35,
      "eval_loss": 1.127606749534607,
      "eval_runtime": 212.9227,
      "eval_samples_per_second": 7.19,
      "eval_steps_per_second": 0.902,
      "step": 1080
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.24957235157489777,
      "learning_rate": 0.0001956730769230769,
      "loss": 1.675,
      "step": 1085
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.13932974636554718,
      "learning_rate": 0.00019519230769230768,
      "loss": 1.6826,
      "step": 1090
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.15158787369728088,
      "learning_rate": 0.00019471153846153846,
      "loss": 1.6182,
      "step": 1095
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.16590507328510284,
      "learning_rate": 0.0001942307692307692,
      "loss": 1.6632,
      "step": 1100
    },
    {
      "epoch": 0.35,
      "eval_loss": 1.1146246194839478,
      "eval_runtime": 212.9123,
      "eval_samples_per_second": 7.191,
      "eval_steps_per_second": 0.902,
      "step": 1100
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.14932048320770264,
      "learning_rate": 0.00019375,
      "loss": 1.6104,
      "step": 1105
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.15189215540885925,
      "learning_rate": 0.00019326923076923077,
      "loss": 1.6708,
      "step": 1110
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.12622776627540588,
      "learning_rate": 0.00019278846153846153,
      "loss": 1.6454,
      "step": 1115
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.16859158873558044,
      "learning_rate": 0.0001923076923076923,
      "loss": 1.6633,
      "step": 1120
    },
    {
      "epoch": 0.36,
      "eval_loss": 1.124027132987976,
      "eval_runtime": 212.9317,
      "eval_samples_per_second": 7.19,
      "eval_steps_per_second": 0.902,
      "step": 1120
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.12753735482692719,
      "learning_rate": 0.00019182692307692303,
      "loss": 1.6464,
      "step": 1125
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.1542394459247589,
      "learning_rate": 0.00019134615384615381,
      "loss": 1.6556,
      "step": 1130
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.13693077862262726,
      "learning_rate": 0.0001908653846153846,
      "loss": 1.6275,
      "step": 1135
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.1769745945930481,
      "learning_rate": 0.00019038461538461535,
      "loss": 1.6386,
      "step": 1140
    },
    {
      "epoch": 0.37,
      "eval_loss": 1.124112844467163,
      "eval_runtime": 214.9283,
      "eval_samples_per_second": 7.123,
      "eval_steps_per_second": 0.893,
      "step": 1140
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.19100803136825562,
      "learning_rate": 0.00018990384615384613,
      "loss": 1.6129,
      "step": 1145
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.1718054860830307,
      "learning_rate": 0.0001894230769230769,
      "loss": 1.6615,
      "step": 1150
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.14379271864891052,
      "learning_rate": 0.00018894230769230766,
      "loss": 1.6184,
      "step": 1155
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.1424819380044937,
      "learning_rate": 0.00018846153846153844,
      "loss": 1.7002,
      "step": 1160
    },
    {
      "epoch": 0.37,
      "eval_loss": 1.1203080415725708,
      "eval_runtime": 212.9707,
      "eval_samples_per_second": 7.189,
      "eval_steps_per_second": 0.902,
      "step": 1160
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.17172783613204956,
      "learning_rate": 0.00018798076923076922,
      "loss": 1.6702,
      "step": 1165
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.1312006711959839,
      "learning_rate": 0.00018749999999999998,
      "loss": 1.5985,
      "step": 1170
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.14062000811100006,
      "learning_rate": 0.00018701923076923076,
      "loss": 1.5949,
      "step": 1175
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.14487944543361664,
      "learning_rate": 0.00018653846153846154,
      "loss": 1.6387,
      "step": 1180
    },
    {
      "epoch": 0.38,
      "eval_loss": 1.1257561445236206,
      "eval_runtime": 212.9569,
      "eval_samples_per_second": 7.189,
      "eval_steps_per_second": 0.902,
      "step": 1180
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.14375077188014984,
      "learning_rate": 0.0001860576923076923,
      "loss": 1.6342,
      "step": 1185
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.15370619297027588,
      "learning_rate": 0.00018557692307692307,
      "loss": 1.6378,
      "step": 1190
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.18638846278190613,
      "learning_rate": 0.00018509615384615382,
      "loss": 1.637,
      "step": 1195
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.1605946570634842,
      "learning_rate": 0.0001846153846153846,
      "loss": 1.6047,
      "step": 1200
    },
    {
      "epoch": 0.38,
      "eval_loss": 1.1167259216308594,
      "eval_runtime": 212.974,
      "eval_samples_per_second": 7.189,
      "eval_steps_per_second": 0.902,
      "step": 1200
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.1771698296070099,
      "learning_rate": 0.00018413461538461539,
      "loss": 1.6562,
      "step": 1205
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.15190012753009796,
      "learning_rate": 0.00018365384615384614,
      "loss": 1.6523,
      "step": 1210
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.14565978944301605,
      "learning_rate": 0.00018317307692307692,
      "loss": 1.6261,
      "step": 1215
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.1377866566181183,
      "learning_rate": 0.00018269230769230767,
      "loss": 1.6787,
      "step": 1220
    },
    {
      "epoch": 0.39,
      "eval_loss": 1.1250168085098267,
      "eval_runtime": 212.9328,
      "eval_samples_per_second": 7.19,
      "eval_steps_per_second": 0.902,
      "step": 1220
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.12782572209835052,
      "learning_rate": 0.00018221153846153843,
      "loss": 1.641,
      "step": 1225
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.12511639297008514,
      "learning_rate": 0.0001817307692307692,
      "loss": 1.6602,
      "step": 1230
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.1462026834487915,
      "learning_rate": 0.00018124999999999996,
      "loss": 1.6193,
      "step": 1235
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.1758279949426651,
      "learning_rate": 0.00018076923076923074,
      "loss": 1.6418,
      "step": 1240
    },
    {
      "epoch": 0.4,
      "eval_loss": 1.1241153478622437,
      "eval_runtime": 212.9715,
      "eval_samples_per_second": 7.189,
      "eval_steps_per_second": 0.902,
      "step": 1240
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.20894353091716766,
      "learning_rate": 0.00018028846153846152,
      "loss": 1.6765,
      "step": 1245
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.13180823624134064,
      "learning_rate": 0.00017980769230769227,
      "loss": 1.6525,
      "step": 1250
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.15477243065834045,
      "learning_rate": 0.00017932692307692306,
      "loss": 1.6929,
      "step": 1255
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.1454429179430008,
      "learning_rate": 0.00017884615384615384,
      "loss": 1.6528,
      "step": 1260
    },
    {
      "epoch": 0.4,
      "eval_loss": 1.1206175088882446,
      "eval_runtime": 212.9487,
      "eval_samples_per_second": 7.19,
      "eval_steps_per_second": 0.902,
      "step": 1260
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.15625090897083282,
      "learning_rate": 0.0001783653846153846,
      "loss": 1.5981,
      "step": 1265
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.1455557495355606,
      "learning_rate": 0.00017788461538461537,
      "loss": 1.6223,
      "step": 1270
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.1587172895669937,
      "learning_rate": 0.00017740384615384615,
      "loss": 1.6483,
      "step": 1275
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.16125497221946716,
      "learning_rate": 0.0001769230769230769,
      "loss": 1.6062,
      "step": 1280
    },
    {
      "epoch": 0.41,
      "eval_loss": 1.1260696649551392,
      "eval_runtime": 212.9326,
      "eval_samples_per_second": 7.19,
      "eval_steps_per_second": 0.902,
      "step": 1280
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.16712862253189087,
      "learning_rate": 0.00017644230769230768,
      "loss": 1.6067,
      "step": 1285
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.18841314315795898,
      "learning_rate": 0.00017596153846153846,
      "loss": 1.6196,
      "step": 1290
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.1874619871377945,
      "learning_rate": 0.00017548076923076922,
      "loss": 1.6263,
      "step": 1295
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.19058579206466675,
      "learning_rate": 0.000175,
      "loss": 1.654,
      "step": 1300
    },
    {
      "epoch": 0.42,
      "eval_loss": 1.122740387916565,
      "eval_runtime": 212.892,
      "eval_samples_per_second": 7.191,
      "eval_steps_per_second": 0.902,
      "step": 1300
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.13527324795722961,
      "learning_rate": 0.00017451923076923078,
      "loss": 1.6682,
      "step": 1305
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.13762807846069336,
      "learning_rate": 0.00017403846153846153,
      "loss": 1.6848,
      "step": 1310
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.21669362485408783,
      "learning_rate": 0.0001735576923076923,
      "loss": 1.6296,
      "step": 1315
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.20022165775299072,
      "learning_rate": 0.00017307692307692304,
      "loss": 1.6667,
      "step": 1320
    },
    {
      "epoch": 0.42,
      "eval_loss": 1.12369704246521,
      "eval_runtime": 214.3402,
      "eval_samples_per_second": 7.143,
      "eval_steps_per_second": 0.896,
      "step": 1320
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.198743537068367,
      "learning_rate": 0.00017259615384615382,
      "loss": 1.5733,
      "step": 1325
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.16169670224189758,
      "learning_rate": 0.0001721153846153846,
      "loss": 1.6123,
      "step": 1330
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.16228975355625153,
      "learning_rate": 0.00017163461538461535,
      "loss": 1.6163,
      "step": 1335
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.14139960706233978,
      "learning_rate": 0.00017115384615384613,
      "loss": 1.6553,
      "step": 1340
    },
    {
      "epoch": 0.43,
      "eval_loss": 1.1238270998001099,
      "eval_runtime": 213.2744,
      "eval_samples_per_second": 7.179,
      "eval_steps_per_second": 0.9,
      "step": 1340
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.14477968215942383,
      "learning_rate": 0.00017067307692307691,
      "loss": 1.6683,
      "step": 1345
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.17151209712028503,
      "learning_rate": 0.00017019230769230767,
      "loss": 1.6312,
      "step": 1350
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.2421816736459732,
      "learning_rate": 0.00016971153846153845,
      "loss": 1.5948,
      "step": 1355
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.17927555739879608,
      "learning_rate": 0.0001692307692307692,
      "loss": 1.6034,
      "step": 1360
    },
    {
      "epoch": 0.44,
      "eval_loss": 1.1228904724121094,
      "eval_runtime": 213.3388,
      "eval_samples_per_second": 7.176,
      "eval_steps_per_second": 0.9,
      "step": 1360
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.16732101142406464,
      "learning_rate": 0.00016874999999999998,
      "loss": 1.6394,
      "step": 1365
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.16357791423797607,
      "learning_rate": 0.00016826923076923076,
      "loss": 1.6378,
      "step": 1370
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.2065645158290863,
      "learning_rate": 0.00016778846153846152,
      "loss": 1.6594,
      "step": 1375
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.1449134200811386,
      "learning_rate": 0.0001673076923076923,
      "loss": 1.5969,
      "step": 1380
    },
    {
      "epoch": 0.44,
      "eval_loss": 1.1282564401626587,
      "eval_runtime": 212.9107,
      "eval_samples_per_second": 7.191,
      "eval_steps_per_second": 0.902,
      "step": 1380
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.15593914687633514,
      "learning_rate": 0.00016682692307692308,
      "loss": 1.6081,
      "step": 1385
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.21112802624702454,
      "learning_rate": 0.00016634615384615383,
      "loss": 1.666,
      "step": 1390
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.18397526443004608,
      "learning_rate": 0.0001658653846153846,
      "loss": 1.6054,
      "step": 1395
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.16171292960643768,
      "learning_rate": 0.0001653846153846154,
      "loss": 1.6489,
      "step": 1400
    },
    {
      "epoch": 0.45,
      "eval_loss": 1.1260366439819336,
      "eval_runtime": 212.9249,
      "eval_samples_per_second": 7.19,
      "eval_steps_per_second": 0.902,
      "step": 1400
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.1328025758266449,
      "learning_rate": 0.00016490384615384614,
      "loss": 1.6441,
      "step": 1405
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.16367842257022858,
      "learning_rate": 0.00016442307692307692,
      "loss": 1.6446,
      "step": 1410
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.19047068059444427,
      "learning_rate": 0.00016394230769230765,
      "loss": 1.5971,
      "step": 1415
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.15220403671264648,
      "learning_rate": 0.00016346153846153843,
      "loss": 1.6485,
      "step": 1420
    },
    {
      "epoch": 0.46,
      "eval_loss": 1.1231212615966797,
      "eval_runtime": 212.975,
      "eval_samples_per_second": 7.189,
      "eval_steps_per_second": 0.902,
      "step": 1420
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.14564599096775055,
      "learning_rate": 0.0001629807692307692,
      "loss": 1.6072,
      "step": 1425
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.19904664158821106,
      "learning_rate": 0.00016249999999999997,
      "loss": 1.6068,
      "step": 1430
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.14457248151302338,
      "learning_rate": 0.00016201923076923075,
      "loss": 1.628,
      "step": 1435
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.14545542001724243,
      "learning_rate": 0.00016153846153846153,
      "loss": 1.6431,
      "step": 1440
    },
    {
      "epoch": 0.46,
      "eval_loss": 1.1277488470077515,
      "eval_runtime": 212.933,
      "eval_samples_per_second": 7.19,
      "eval_steps_per_second": 0.902,
      "step": 1440
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.13858167827129364,
      "learning_rate": 0.00016105769230769228,
      "loss": 1.6225,
      "step": 1445
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.14832210540771484,
      "learning_rate": 0.00016057692307692306,
      "loss": 1.6563,
      "step": 1450
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.1761961281299591,
      "learning_rate": 0.00016009615384615384,
      "loss": 1.5855,
      "step": 1455
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.19360747933387756,
      "learning_rate": 0.0001596153846153846,
      "loss": 1.6615,
      "step": 1460
    },
    {
      "epoch": 0.47,
      "eval_loss": 1.131932020187378,
      "eval_runtime": 212.9614,
      "eval_samples_per_second": 7.189,
      "eval_steps_per_second": 0.902,
      "step": 1460
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.14600206911563873,
      "learning_rate": 0.00015913461538461537,
      "loss": 1.6442,
      "step": 1465
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.20899981260299683,
      "learning_rate": 0.00015865384615384616,
      "loss": 1.6315,
      "step": 1470
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.1724894493818283,
      "learning_rate": 0.0001581730769230769,
      "loss": 1.6428,
      "step": 1475
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.21148432791233063,
      "learning_rate": 0.0001576923076923077,
      "loss": 1.6048,
      "step": 1480
    },
    {
      "epoch": 0.47,
      "eval_loss": 1.1336439847946167,
      "eval_runtime": 212.9206,
      "eval_samples_per_second": 7.19,
      "eval_steps_per_second": 0.902,
      "step": 1480
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.23908506333827972,
      "learning_rate": 0.00015721153846153844,
      "loss": 1.6212,
      "step": 1485
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.17056453227996826,
      "learning_rate": 0.00015673076923076922,
      "loss": 1.6785,
      "step": 1490
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.13311614096164703,
      "learning_rate": 0.00015625,
      "loss": 1.6594,
      "step": 1495
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.16127556562423706,
      "learning_rate": 0.00015576923076923076,
      "loss": 1.6429,
      "step": 1500
    },
    {
      "epoch": 0.48,
      "eval_loss": 1.1252208948135376,
      "eval_runtime": 212.942,
      "eval_samples_per_second": 7.19,
      "eval_steps_per_second": 0.902,
      "step": 1500
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.14715708792209625,
      "learning_rate": 0.00015528846153846154,
      "loss": 1.6255,
      "step": 1505
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.15508805215358734,
      "learning_rate": 0.00015480769230769232,
      "loss": 1.6566,
      "step": 1510
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.15982072055339813,
      "learning_rate": 0.00015432692307692304,
      "loss": 1.6485,
      "step": 1515
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.18296901881694794,
      "learning_rate": 0.00015384615384615382,
      "loss": 1.5977,
      "step": 1520
    },
    {
      "epoch": 0.49,
      "eval_loss": 1.1257035732269287,
      "eval_runtime": 212.8908,
      "eval_samples_per_second": 7.191,
      "eval_steps_per_second": 0.902,
      "step": 1520
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.15000808238983154,
      "learning_rate": 0.00015336538461538458,
      "loss": 1.6201,
      "step": 1525
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.16645129024982452,
      "learning_rate": 0.00015288461538461536,
      "loss": 1.6318,
      "step": 1530
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.1527809351682663,
      "learning_rate": 0.00015240384615384614,
      "loss": 1.6552,
      "step": 1535
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.1833203285932541,
      "learning_rate": 0.0001519230769230769,
      "loss": 1.6041,
      "step": 1540
    },
    {
      "epoch": 0.49,
      "eval_loss": 1.12226140499115,
      "eval_runtime": 212.9313,
      "eval_samples_per_second": 7.19,
      "eval_steps_per_second": 0.902,
      "step": 1540
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.15028104186058044,
      "learning_rate": 0.00015144230769230767,
      "loss": 1.6084,
      "step": 1545
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.148651123046875,
      "learning_rate": 0.00015096153846153845,
      "loss": 1.6507,
      "step": 1550
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.20607829093933105,
      "learning_rate": 0.0001504807692307692,
      "loss": 1.635,
      "step": 1555
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.19219490885734558,
      "learning_rate": 0.00015,
      "loss": 1.6082,
      "step": 1560
    },
    {
      "epoch": 0.5,
      "eval_loss": 1.1237365007400513,
      "eval_runtime": 212.9474,
      "eval_samples_per_second": 7.19,
      "eval_steps_per_second": 0.902,
      "step": 1560
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.17378468811511993,
      "learning_rate": 0.00014951923076923077,
      "loss": 1.6361,
      "step": 1565
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.21558412909507751,
      "learning_rate": 0.00014903846153846152,
      "loss": 1.617,
      "step": 1570
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.18948113918304443,
      "learning_rate": 0.0001485576923076923,
      "loss": 1.624,
      "step": 1575
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.19080808758735657,
      "learning_rate": 0.00014807692307692308,
      "loss": 1.6167,
      "step": 1580
    },
    {
      "epoch": 0.51,
      "eval_loss": 1.1261628866195679,
      "eval_runtime": 212.9058,
      "eval_samples_per_second": 7.191,
      "eval_steps_per_second": 0.902,
      "step": 1580
    }
  ],
  "logging_steps": 5,
  "max_steps": 3120,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 20,
  "total_flos": 8.580358706429952e+17,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
